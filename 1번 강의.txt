주먹왕랄프2 검색

랄프 breaksd internet search

조은 미디움

개발자로 집중하면 좋은게 

데이털ㄹ 모으는 과정

크롤링을 하는것

구글봇- 크롤링 봇

전통적입 웹사이트 -- 콘텐츠는 서버에서 만들고 
클라이언트는 완성된 콘텐츠를 받는 역할

그래서 p라는게 있어서 그걸 인식하는건데

근래에는
서버는 api를 만들어놓고

fetchapi라던지 데이터를 주고 받는 애들을 생성하게 된다

제일 중요한건 컨텐츠를 자바스크립트로 생성한다

그래서 최근에는 자바스크립트 실행없이 컨텐츠가 만들어지지 않는다

따라서 SPA는 검새이 안된다?

구글봇에 대해 이해하는게 우리의 page를 상위랭크하는게 좋다


크롬으로 rendering해주게 되는데

4주에 한번씩 release되고있는 시점에서

JS는 최근 빠르게 발전하고있꼬
V8도 크롬과 같이 같이 나아간다

Puppeteer 를 이용해서 페이지를 랜더링하고 수집할수있게 바뀌었다
헤드리스 모드를 가지고 어떻게 돌아가는지 확인해볼수 있다.

E2E 나 unit test를 할때 확인해볼수있는 용도로 사용할수 있다


따라서 SPA는 검색결과에 영향을 미치지 않는다


SPA 가 아무리 빨라도 SSR보다 느리다   server side rendering보다 느리다

serverside rendering과 spa 를 적절히 섞어서 쓰는게 좋다

spa의 기능때문에 하위노출되는 적은 있어도


************SEO 검색엔진에서 상위노출되도록 수정하는 방법

검색엔진이 어떻게 돌아가는지


web master conference 에서도 구글검색이 어떻게 동작하는지 모른다

구글검색의 core를 건드리는 사람만 300명정도고

수많은 알고리즘이 구글검색에 쌓이게 된다

이런 parser와 이런rank시스템으로 구글봇으로 가져온다
라는것을 많이 노출하므로
이러한 정보를 바탕으로 상위 노출시키는 방향으로 가는게 좋겠따


Robots.txt@@@@@@@@@@@@@@@2

구글봇의 웹컨텐츠 접근권한을 제어하는 파일


curs막혀있어도 긁어볼수있꼬

Mnet의 API가 노출되어서 cracking해볼수있다

딱히 막을게 없다면 Robots을 추가할필요없다

구글검색결과에 노출은 되지만


네이버 같은경우에는 disallow / 를 해놓아서 전체가 다 검색안되게 해놓았다
따라서 이런경우는 정말 안좋다 네이버 검색은 되는데 구글검색은 안되는 정도이고


Disallow 에 admin이 들어가있다면
url/robots.txt로 들어갈수있게되므로 해당부분이 취약함을 알려주는 역할이다

-------- 검색이 안되게 하려면 
1.아예 도메인을 분리하는것이다 sub domain으로 


2. 로그인이 반드시 필요한 page는 검색되지 않는다


7/1 robots.txt의 update 
google이 25주년을 맞이해 표준을 만드려 한다

robots.txt의 parser를 공개했기때문에 우리 page나 어떤 page를 화깅ㄴ해볼수있따.

지금까지는 이렇게 하겠지로 짐작했지만 앞으로는 이렇게 하는구나 라고 생각해볼수있따

네이버 검색에 집중하지말고 구글에 집중해보자

@@@@@@@@@@@2올바른 title값사용
worst case
모든 content의 제목을 동일하게 설정하는것

애매한 사례
구분은 ㅇ되어있지만 어디서 호스팅되는지 모르는 제목들

콘텐츠를 설명하는 title을 사용하면서, site를 잘설명하고있는경우

<title> 맥주 레시피 - 회사 이름</title>


@@@@@@@@@description 사용

각콘텐츠를 짧게 설명하는 description을 사용하자

1. description을 선언안하는 경우는 안좋고

2. og:description만 선언하는 것도 안좋다

따라서 og랑 description으로 하면된다

description을 잘 하면 
신뢰도도 올라가고 좋다



ECMA Scripts나 그런것들을  좋지않다


@@@@@@@@@@HTML을 잘 사용해야 구글검색에 잘 노출이 된다

이동할때는 a태그로

구글봇이 rendering하기 위해서
구글보싱 전부 rendering해서 content를 가져오야되고

a요소를 전부 찾아서 graph를 그리게 된다

구글봇은 성능걱정을 할 필요 없을정도로 빠르게 동작한다

따라서 a태그만 잘 작성해줘도 좋아진다

site는 잘만들었는데 subpage를 안가져간다?
구글페이지가 리소스를 절약하기위해 온클릭 이벤트같은거는 안가져오고
a만 가져오게 된다

@@@@@@@제목은 제목요소로 선언하는 것이 좋다

heading요소를 잘 사용해야하는것은 h1~h6를 보면서 outline을 그리게 되는것이다

따라서 outline이 잘 그려진 site가 상위노출 되게 된다

@@@@@@@모바일을 지원하는 페이지일수록 우선적으로 노출시키낟
구글의 모바일 검색과 데스크탑이 순위가 다른게 아닌데
모바일+데스크탑 > 모바일 > 데스크탑

따라서 반응형 웹디자인으로 만드는것이 중요하다//////

모바일 지원하는지 어떻게 아는가?

viewport? nono

layout을 봤을때 특정 viewport에서 content가 넘어가는 경우 모바일이 지원되지 않는다고 생각하고
이를 이용해 검색한다


Structured data 

html을 넘어서 콘텐츠기 어떤 데이터 인지 나타낸다

schema.org 라고 정의되어있는것에서 사용하면 된다


구글이 크롤링하고 있는게 경의 단위가 넘어간다


따라서 레시피라고 인식되게 하려면 
item type으로 하고 
item prop도 선언해주고

그럼 레시피라고 검색을 하면 최상단 노출이 된다


google search가 지원하는 범위


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
좋은것은 알겠는데 언제 다챙길까

Lighthouse라는 도구를 사용함녀 도움이 된다

ㅋ롬이 기본적으로 사용되어있는 웹페이지 종합 검사 도구

teminal에서 사용가능하고
ci에 적용해 PR을 날려서 검사하는것도 가능하다


퍼포먼스가 낮아도 접근성이 좋다는 것은 중요하다

web.dev로 들어가게되면 각각의 항목이 어떤코드로 우리 사이트를 평가하는지 알수있다


그외에도 검색에 중요한것

1. 속도가 빨라야한다( 구글에서 웹페이지 속도가 빨라야하는 기준- 1초이내)
우리가 구현한건 3g에서도 1초이내에
2.  모바일을 지원해야한다

따라서 구글검색에서 상위노출이 되는것은 어렵다

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
나무위키가 seo가 잘되어있다
content의 신뢰와 상관없이

뉴욕타임즈나 가디언 사이트 같은경우 참고가 잘되어있어서 좋다
apes0123@gamil.com


